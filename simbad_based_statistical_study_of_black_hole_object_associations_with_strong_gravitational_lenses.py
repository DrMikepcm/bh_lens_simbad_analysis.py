# -*- coding: utf-8 -*-
"""SIMBAD-based statistical study of black hole object associations with strong gravitational lenses

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15tL51-98QAsQhEk0-FEL7cKi5pTSBVSq
"""

# 1️⃣ Install lenscat (if not already done)
!pip install lenscat

# 2️⃣ Load the full catalog
import lenscat
from astropy.table import Table

print("Loading full catalog from lenscat package...")
catalog: Table = lenscat.catalog  # This pulls in all ~32 k lenses
print(f"✅ Total lenses loaded: {len(catalog):,}")

# 3️⃣ Show grading breakdown and filter
import numpy as np
import pandas as pd

df = catalog.to_pandas()
print("\nGrading counts:")
print(df['grading'].value_counts())

# 4️⃣ Focus on strong lenses with redshift
df_strong = df[df['grading'].isin(['confident', 'probable'])].copy()
df_strong['z'] = pd.to_numeric(df_strong['zlens'], errors='coerce')
df_strong = df_strong.dropna(subset=['z']).reset_index(drop=True)
print(f"\nStrong lenses w/ redshift: {len(df_strong):,}")

!pip install astropy astroquery scipy



# Step 2: Import libraries
import pandas as pd
import numpy as np
import random
from astropy.coordinates import SkyCoord
import astropy.units as u
from astroquery.simbad import Simbad
from scipy.stats import chi2_contingency, poisson
import time

# Step 3: Load lens catalog # 1️⃣ Install lenscat (if not already done)
!pip install lenscat

# 2️⃣ Load the full catalog
import lenscat
from astropy.table import Table

print("Loading full catalog from lenscat package...")
catalog: Table = lenscat.catalog  # This pulls in all ~32 k lenses
print(f"✅ Total lenses loaded: {len(catalog):,}")

# 3️⃣ Show grading breakdown and filter
import numpy as np
import pandas as pd

df = catalog.to_pandas()
print("\nGrading counts:")
print(df['grading'].value_counts())

# 4️⃣ Focus on strong lenses with redshift
df_strong = df[df['grading'].isin(['confident', 'probable'])].copy()
df_strong['z'] = pd.to_numeric(df_strong['zlens'], errors='coerce')
df_strong = df_strong.dropna(subset=['z']).reset_index(drop=True)
print(f"\nStrong lenses w/ redshift: {len(df_strong):,}")

# Step 4: Filter for confident lenses with valid redshift
df_confident = df[df['grading'] == 'confident'].copy()
df_confident['z'] = pd.to_numeric(df_confident['zlens'], errors='coerce')
df_confident = df_confident.dropna(subset=['z']).reset_index(drop=True)

print(f"Confident lenses with usable redshift: {len(df_confident)}")

# Step 5: Split lenses into batches of 50
batch_size = 50
batches = [df_confident.iloc[i:i + batch_size] for i in range(0, len(df_confident), batch_size)]
print(f"Total batches: {len(batches)}")

# Step 6: Get all lens coordinates to avoid overlaps
all_lens_coords = SkyCoord(ra=df_confident['RA'].values * u.deg, dec=df_confident['DEC'].values * u.deg)

# Step 7: Helper function to generate random points avoiding any lens within min_sep arcmin
def generate_random_points(n_points, min_sep_arcmin=20):
    points = []
    attempts = 0
    max_attempts = n_points * 100  # safety cap

    while len(points) < n_points and attempts < max_attempts:
        ra_rand = random.uniform(0, 360)
        dec_rand = random.uniform(-90, 90)
        coord = SkyCoord(ra=ra_rand * u.deg, dec=dec_rand * u.deg)
        # Check minimum separation to ALL lenses
        sep = coord.separation(all_lens_coords).arcminute
        if np.all(sep > min_sep_arcmin):
            points.append(coord)
        attempts += 1
    if len(points) < n_points:
        print(f"Warning: Only generated {len(points)} random points after {attempts} attempts")
    return points

# Step 8: Setup SIMBAD query for BH-type objects
custom_simbad = Simbad()
custom_simbad.TIMEOUT = 60
custom_simbad.remove_votable_fields('*')
custom_simbad.add_votable_fields('otype')

bh_types = ['BH', 'BHXRB', 'XRB', 'BLAZAR', 'AGN', 'QSO']

def query_bh_counts(coord, radius_arcmin=10):
    radius = radius_arcmin * u.arcmin
    try:
        result = custom_simbad.query_region(coord, radius=radius)
        if result is None:
            return 0
        # Count BH-related objects
        count = sum(any(bh in otype for bh in bh_types) for otype in result['OTYPE'])
        return count
    except Exception as e:
        print(f"SIMBAD query failed at {coord.to_string('hmsdms')}: {e}")
        return None

# Step 9: For each batch, query BH counts for lenses and matching random points
radii = [10, 15, 20]  # arcminutes
results = []

for batch_i, batch_df in enumerate(batches, 1):
    print(f"\nProcessing batch {batch_i} with {len(batch_df)} lenses...")
    lens_coords = SkyCoord(ra=batch_df['RA'].values * u.deg, dec=batch_df['DEC'].values * u.deg)

    # Generate matching random points avoiding ALL lenses
    random_points = generate_random_points(len(batch_df), min_sep_arcmin=20)

    for radius in radii:
        print(f"Radius: {radius} arcmin")

        # Query lenses
        lens_counts = []
        for coord in lens_coords:
            c = query_bh_counts(coord, radius)
            while c is None:  # retry if failed
                time.sleep(5)
                c = query_bh_counts(coord, radius)
            lens_counts.append(c)

        # Query random points
        random_counts = []
        for coord in random_points:
            c = query_bh_counts(coord, radius)
            while c is None:
                time.sleep(5)
                c = query_bh_counts(coord, radius)
            random_counts.append(c)

        # Compute % with >=1 BH-type object
        lens_positive = sum(c > 0 for c in lens_counts)
        random_positive = sum(c > 0 for c in random_counts)
        n_lens = len(lens_counts)
        n_random = len(random_counts)
        lens_frac = lens_positive / n_lens
        random_frac = random_positive / n_random

        # Chi-squared test on 2x2 table
        contingency = [[lens_positive, n_lens - lens_positive],
                       [random_positive, n_random - random_positive]]
        chi2, p, _, _ = chi2_contingency(contingency)

        # Mean counts per field
        mean_lens = np.mean(lens_counts)
        mean_random = np.mean(random_counts)

        # Poisson test on total counts
        total_lens = sum(lens_counts)
        total_random = sum(random_counts)
        # (Using Poisson for approximate test of difference)
        poisson_p = poisson.sf(total_lens - 1, total_random)  # survival function

        results.append({
            'batch': batch_i,
            'radius_arcmin': radius,
            'lens_positive_frac': lens_frac,
            'random_positive_frac': random_frac,
            'chi2_pvalue': p,
            'mean_lens_count': mean_lens,
            'mean_random_count': mean_random,
            'poisson_pvalue': poisson_p
        })

        print(f"Lenses with BH≥1: {lens_positive}/{n_lens} ({lens_frac:.3f})")
        print(f"Randoms with BH≥1: {random_positive}/{n_random} ({random_frac:.3f})")
        print(f"Chi2 p-value: {p:.4f}, Poisson p-value: {poisson_p:.4f}")
        print(f"Mean counts - Lenses: {mean_lens:.2f}, Randoms: {mean_random:.2f}")

# Step 10: Convert results to DataFrame for further analysis or export
df_results = pd.DataFrame(results)
print("\nSummary of all batches:")
print(df_results)

# Step 1: Imports
import pandas as pd
import numpy as np
import random
import time
from astropy.coordinates import SkyCoord
import astropy.units as u
from astroquery.simbad import Simbad
from scipy.stats import chi2_contingency, poisson

# Step 2: Load lenscat catalog
from lenscat import catalog  # Assumes installed manually in environment
from astropy.table import Table

print("Loading full catalog from lenscat package...")
df = catalog.to_pandas()
print(f"✅ Total lenses loaded: {len(df):,}")

# Step 3: Filter strong lenses with valid redshift
df_strong = df[df['grading'].isin(['confident', 'probable'])].copy()
df_strong['z'] = pd.to_numeric(df_strong['zlens'], errors='coerce')
df_strong = df_strong.dropna(subset=['z']).reset_index(drop=True)
print(f"Strong lenses w/ redshift: {len(df_strong):,}")

# Step 4: Filter for confident lenses only (used for analysis)
df_confident = df[df['grading'] == 'confident'].copy()
df_confident['z'] = pd.to_numeric(df_confident['zlens'], errors='coerce')
df_confident = df_confident.dropna(subset=['z']).reset_index(drop=True)
print(f"Confident lenses with usable redshift: {len(df_confident)}")

# Step 5: Create batches
batch_size = 50
batches = [df_confident.iloc[i:i + batch_size] for i in range(0, len(df_confident), batch_size)]
print(f"Total batches: {len(batches)}")

# Step 6: Get all lens coordinates for random point exclusion
all_lens_coords = SkyCoord(ra=df_confident['RA'].values * u.deg,
                           dec=df_confident['DEC'].values * u.deg)

# Step 7: Generate random points that avoid any known lens
def generate_random_points(n_points, min_sep_arcmin=20):
    points = []
    attempts = 0
    max_attempts = n_points * 100

    while len(points) < n_points and attempts < max_attempts:
        ra_rand = random.uniform(0, 360)
        dec_rand = random.uniform(-90, 90)
        coord = SkyCoord(ra=ra_rand * u.deg, dec=dec_rand * u.deg)
        sep = coord.separation(all_lens_coords).arcminute
        if np.all(sep > min_sep_arcmin):
            points.append(coord)
        attempts += 1

    if len(points) < n_points:
        print(f"⚠️ Only generated {len(points)} random points after {attempts} attempts")
    return points

# Step 8: Setup SIMBAD for BH-type search (fixed for newer astroquery)
custom_simbad = Simbad()
custom_simbad.TIMEOUT = 60
custom_simbad.VOTABLE_FIELDS = ['otype']  # compatible alternative to deprecated method
custom_simbad = Simbad()
custom_simbad.TIMEOUT = 60
custom_simbad.VOTABLE_FIELDS = ['otype']  # compatible alternative to deprecated method


bh_types = ['BH', 'BHXRB', 'XRB', 'BLAZAR', 'AGN', 'QSO']

# Step 9: Analyze batches
radii = [10, 15, 20]
results = []

for batch_i, batch_df in enumerate(batches, 1):
    print(f"\n🔎 Processing batch {batch_i} ({len(batch_df)} lenses)...")
    lens_coords = SkyCoord(ra=batch_df['RA'].values * u.deg, dec=batch_df['DEC'].values * u.deg)
    random_points = generate_random_points(len(batch_df), min_sep_arcmin=20)

    for radius in radii:
        print(f"▶ Radius: {radius}′")

        # Query BH counts for lenses
        lens_counts = []
        for coord in lens_coords:
            c = query_bh_counts(coord, radius)
            while c is None:
                time.sleep(5)
                c = query_bh_counts(coord, radius)
            lens_counts.append(c)

        # Query BH counts for randoms
        random_counts = []
        for coord in random_points:
            c = query_bh_counts(coord, radius)
            while c is None:
                time.sleep(5)
                c = query_bh_counts(coord, radius)
            random_counts.append(c)

        # Calculate stats
        lens_positive = sum(c > 0 for c in lens_counts)
        random_positive = sum(c > 0 for c in random_counts)
        n_lens = len(lens_counts)
        n_random = len(random_counts)

        contingency = [[lens_positive, n_lens - lens_positive],
                       [random_positive, n_random - random_positive]]
        chi2, chi2_p, _, _ = chi2_contingency(contingency)

        mean_lens = np.mean(lens_counts)
        mean_random = np.mean(random_counts)
        total_lens = sum(lens_counts)
        total_random = sum(random_counts)
        poisson_p = poisson(mu=total_random).sf(total_lens - 1)

        results.append({
            'batch': batch_i,
            'radius_arcmin': radius,
            'lens_positive_frac': lens_positive / n_lens,
            'random_positive_frac': random_positive / n_random,
            'chi2_pvalue': chi2_p,
            'mean_lens_count': mean_lens,
            'mean_random_count': mean_random,
            'poisson_pvalue': poisson_p
        })

        print(f"✅ BH≥1 — Lenses: {lens_positive}/{n_lens} ({lens_positive / n_lens:.2f}) | "
              f"Randoms: {random_positive}/{n_random} ({random_positive / n_random:.2f})")
        print(f"   Chi² p = {chi2_p:.2e}, Poisson p = {poisson_p:.2e}")
        print(f"   Mean BH count — Lenses: {mean_lens:.2f}, Randoms: {mean_random:.2f}")

# Step 10: Save and display results
df_results = pd.DataFrame(results)
print("\n📊 Summary of all batches:")
print(df_results)

# Step 1: Imports
import pandas as pd
import numpy as np
import random
import time
from astropy.coordinates import SkyCoord
import astropy.units as u
from astroquery.simbad import Simbad
from scipy.stats import chi2_contingency, poisson
from lenscat import catalog  # Assumes installed

# Step 2: Load full catalog
print("Loading full catalog from lenscat package...")
df = catalog.to_pandas()
print(f"✅ Total lenses loaded: {len(df):,}")

# Step 3: Filter lenses with redshift
df_strong = df[df['grading'].isin(['confident', 'probable'])].copy()
df_strong['z'] = pd.to_numeric(df_strong['zlens'], errors='coerce')
df_strong = df_strong.dropna(subset=['z']).reset_index(drop=True)
print(f"Strong lenses w/ redshift: {len(df_strong):,}")

# Step 4: Filter for confident lenses only
df_confident = df[df['grading'] == 'confident'].copy()
df_confident['z'] = pd.to_numeric(df_confident['zlens'], errors='coerce')
df_confident = df_confident.dropna(subset=['z']).reset_index(drop=True)
print(f"Confident lenses with usable redshift: {len(df_confident)}")

# Step 5: Create batches
batch_size = 50
batches = [df_confident.iloc[i:i + batch_size] for i in range(0, len(df_confident), batch_size)]
print(f"Total batches: {len(batches)}")

# Step 6: Prepare all lens coordinates for random point exclusion
all_lens_coords = SkyCoord(ra=df_confident['RA'].values * u.deg,
                           dec=df_confident['DEC'].values * u.deg)

# Step 7: Random point generator
def generate_random_points(n_points, min_sep_arcmin=20):
    points = []
    attempts = 0
    max_attempts = n_points * 100
    while len(points) < n_points and attempts < max_attempts:
        ra_rand = random.uniform(0, 360)
        dec_rand = random.uniform(-90, 90)
        coord = SkyCoord(ra=ra_rand * u.deg, dec=dec_rand * u.deg)
        sep = coord.separation(all_lens_coords).arcminute
        if np.all(sep > min_sep_arcmin):
            points.append(coord)
        attempts += 1
    if len(points) < n_points:
        print(f"⚠️ Only generated {len(points)} random points after {attempts} attempts")
    return points

# Step 8: Configure SIMBAD
custom_simbad = Simbad()
custom_simbad.TIMEOUT = 60
custom_simbad.VOTABLE_FIELDS = ['otype']  # Fix for newer astroquery

bh_types = ['BH', 'BHXRB', 'XRB', 'BLAZAR', 'AGN', 'QSO']

# Step 9: Define SIMBAD query function
def query_bh_counts(coord, radius_arcmin=10):
    radius = radius_arcmin * u.arcmin
    try:
        result = custom_simbad.query_region(coord, radius=radius)
        if result is None:
            return 0
        return sum(any(bh in otype for bh in bh_types) for otype in result['OTYPE'])
    except Exception as e:
        print(f"SIMBAD query failed at {coord.to_string('hmsdms')}: {e}")
        return None

# Step 10: Run analysis for each batch
radii = [10, 15, 20]  # arcmin
results = []

for batch_i, batch_df in enumerate(batches, 1):
    print(f"\n🔎 Processing batch {batch_i} ({len(batch_df)} lenses)...")
    lens_coords = SkyCoord(ra=batch_df['RA'].values * u.deg, dec=batch_df['DEC'].values * u.deg)
    random_points = generate_random_points(len(batch_df), min_sep_arcmin=20)

    for radius in radii:
        print(f"▶ Radius: {radius}′")

        # Query lens fields
        lens_counts = []
        for coord in lens_coords:
            c = query_bh_counts(coord, radius)
            while c is None:
                time.sleep(5)
                c = query_bh_counts(coord, radius)
            lens_counts.append(c)

        # Query random fields
        random_counts = []
        for coord in random_points:
            c = query_bh_counts(coord, radius)
            while c is None:
                time.sleep(5)
                c = query_bh_counts(coord, radius)
            random_counts.append(c)

        # Stats
# Step 11: Final summary
df_results = pd.DataFrame(results)
print("\n📊 Summary of all batches:")
print(df_results)

# Step 1: Imports
import pandas as pd
import numpy as np
import random
import time
from astropy.coordinates import SkyCoord
import astropy.units as u
from astroquery.simbad import Simbad
from scipy.stats import chi2_contingency, poisson
from lenscat import catalog  # Assumes installed

# Step 2: Load catalog
print("Loading full catalog from lenscat package...")
df = catalog.to_pandas()
print(f"✅ Total lenses loaded: {len(df):,}")

# Step 3: Filter lenses with redshift
df_strong = df[df['grading'].isin(['confident', 'probable'])].copy()
df_strong['z'] = pd.to_numeric(df_strong['zlens'], errors='coerce')
df_strong = df_strong.dropna(subset=['z']).reset_index(drop=True)
print(f"Strong lenses w/ redshift: {len(df_strong):,}")

# Step 4: Use confident lenses for analysis
df_confident = df[df['grading'] == 'confident'].copy()
df_confident['z'] = pd.to_numeric(df_confident['zlens'], errors='coerce')
df_confident = df_confident.dropna(subset=['z']).reset_index(drop=True)
print(f"Confident lenses with usable redshift: {len(df_confident)}")

# Step 5: Create batches
batch_size = 50
batches = [df_confident.iloc[i:i + batch_size] for i in range(0, len(df_confident), batch_size)]
print(f"Total batches: {len(batches)}")

# Step 6: Prepare all lens coordinates for exclusion
all_lens_coords = SkyCoord(ra=df_confident['RA'].values * u.deg,
                           dec=df_confident['DEC'].values * u.deg)

# Step 7: Random point generator
def generate_random_points(n_points, min_sep_arcmin=20):
    points = []
    attempts = 0
    max_attempts = n_points * 100
    while len(points) < n_points and attempts < max_attempts:
        ra_rand = random.uniform(0, 360)
        dec_rand = random.uniform(-90, 90)
        coord = SkyCoord(ra=ra_rand * u.deg, dec=dec_rand * u.deg)
        sep = coord.separation(all_lens_coords).arcminute
        if np.all(sep > min_sep_arcmin):
            points.append(coord)
        attempts += 1
    if len(points) < n_points:
        print(f"⚠️ Only generated {len(points)} random points after {attempts} attempts")
    return points

# Step 8: Configure SIMBAD
custom_simbad = Simbad()
custom_simbad.TIMEOUT = 60
custom_simbad.VOTABLE_FIELDS = ['otype']  # only return object types

bh_types = ['BH', 'BHXRB', 'XRB', 'BLAZAR', 'AGN', 'QSO']

# Step 9: Query SIMBAD for BH-related object count near a coordinate
def query_bh_counts(coord, radius_arcmin=10):
    radius = radius_arcmin * u.arcmin
    try:
        result = custom_simbad.query_region(coord, radius=radius)
        if result is None or 'OTYPE' not in result.colnames:
            return 0
        return sum(
            any(bh in (otype or '') for bh in bh_types)
            for otype in result['OTYPE']
        )
    except Exception as e:
        print(f"SIMBAD query failed at {coord.to_string('hmsdms')}: {e}")
        return None

# Step 10: Retry wrapper to prevent infinite loops
def safe_query(coord, radius, max_retries=3):
    retries = 0
    while retries < max_retries:
        c = query_bh_counts(coord, radius)
        if c is not None:
            return c
        retries += 1
        time.sleep(5)
    print(f"⚠️ Giving up on {coord.to_string('hmsdms')} after {max_retries} retries")
    return 0

# Step 11: Process batches
radii = [10, 15, 20]
results = []

for batch_i, batch_df in enumerate(batches, 1):
    print(f"\n🔎 Processing batch {batch_i} ({len(batch_df)} lenses)...")
    lens_coords = SkyCoord(ra=batch_df['RA'].values * u.deg, dec=batch_df['DEC'].values * u.deg)
    random_points = generate_random_points(len(batch_df), min_sep_arcmin=20)

    for radius in radii:
        print(f"▶ Radius: {radius}′")

        # Query lenses
        lens_counts = [safe_query(coord, radius) for coord in lens_coords]

        # Query randoms
        random_counts = [safe_query(coord, radius) for coord in random_points]

        # Compute stats
# Step 12: Output final results
df_results = pd.DataFrame(results)
print("\n📊 Summary of all batches:")
print(df_results)

import numpy as np
import pandas as pd
from lenscat import catalog
from astropy.coordinates import SkyCoord
from astroquery.simbad import Simbad
import astropy.units as u
from scipy.stats import chi2_contingency, binomtest, poisson
import random

# Setup SIMBAD
custom_simbad = Simbad()
custom_simbad.TIMEOUT = 60
custom_simbad.remove_votable_fields()
custom_simbad.add_votable_fields("otype")

# BH-like object types
bh_types = {"BH", "BHXRB", "XRB", "BLAZAR", "AGN", "QSO"}

# Load catalog and filter confident lenses with redshift
df = catalog.to_pandas()
df_confident = df[df["grading"] == "confident"].copy()
df_confident["z"] = pd.to_numeric(df_confident["zlens"], errors="coerce")
df_confident = df_confident.dropna(subset=["z"]).reset_index(drop=True)

print(f"✅ Loaded {len(df)} lenses from catalog")
print(f"Confident lenses with usable redshift: {len(df_confident)}")

# Prepare coordinates of all lenses to avoid overlap with randoms
all_lens_coords = SkyCoord(ra=df["RA"].values * u.deg, dec=df["DEC"].values * u.deg)

# Parameters
radii = [10, 15, 20]  # arcminutes
batch_size = 50
batches = [df_confident[i:i+batch_size] for i in range(0, len(df_confident), batch_size)]

results = []

for batch_num, batch in enumerate(batches, 1):
    print(f"\n🔎 Processing batch {batch_num} ({len(batch)} lenses)...")

    # Lens coordinates
    lens_coords = SkyCoord(ra=batch["RA"].values * u.deg, dec=batch["DEC"].values * u.deg)

    # Generate non-overlapping random coordinates
    random_coords = []
    attempts = 0
    while len(random_coords) < len(batch) and attempts < 1000:
        ra = random.uniform(0, 360)
        dec = random.uniform(-30, 80)  # Avoid Galactic plane and poles
        coord = SkyCoord(ra=ra * u.deg, dec=dec * u.deg)
        sep = coord.separation(all_lens_coords).min()
        if sep.deg > 0.3:
            random_coords.append(coord)
        attempts += 1
    random_coords = random_coords[:len(batch)]

    for radius in radii:
        r = radius * u.arcmin
        lens_counts = []
        rand_counts = []

        # Query lenses
        for coord in lens_coords:
            try:
                result = custom_simbad.query_region(coord, radius=r)
                if result:
                    types = set(result['OTYPE'])
                    count = sum(t in bh_types for t in types)
                    lens_counts.append(count)
                else:
                    lens_counts.append(0)
            except Exception as e:
                lens_counts.append(0)

        # Query randoms
        for coord in random_coords:
            try:
                result = custom_simbad.query_region(coord, radius=r)
                if result:
                    types = set(result['OTYPE'])
                    count = sum(t in bh_types for t in types)
                    rand_counts.append(count)
                else:
                    rand_counts.append(0)
            except Exception as e:
                rand_counts.append(0)

        # Aggregate
        lens_nonzero = sum(c > 0 for c in lens_counts)
        rand_nonzero = sum(c > 0 for c in rand_counts)
        lens_zero = len(lens_counts) - lens_nonzero
        rand_zero = len(rand_counts) - rand_nonzero

        # Chi-squared
        table = [[lens_nonzero, lens_zero], [rand_nonzero, rand_zero]]
        chi2, p_chi2, _, _ = chi2_contingency(table)

        # Binomial (lens nonzero vs. expected rate from randoms)
        expected_rate = rand_nonzero / len(rand_counts) if rand_counts else 0.01
        p_binom = binomtest(lens_nonzero, len(lens_counts), expected_rate).pvalue

        # Poisson comparison (mean count)
        lens_mean = np.mean(lens_counts)
        rand_mean = np.mean(rand_counts)
        p_poisson = poisson.cdf(lens_nonzero, mu=rand_nonzero) if rand_nonzero > 0 else 1.0

        results.append({
            "batch": batch_num,
            "radius_arcmin": radius,
            "lens_nonzero": lens_nonzero,
            "lens_total": len(lens_counts),
            "rand_nonzero": rand_nonzero,
            "rand_total": len(rand_counts),
            "lens_mean": lens_mean,
            "rand_mean": rand_mean,
            "p_chi2": p_chi2,
            "p_binom": p_binom,
            "p_poisson": p_poisson
        })

# Results summary
df_results = pd.DataFrame(results)
print("\n📊 Combined Summary:")
print(df_results.groupby("radius_arcmin").agg({
    "lens_nonzero": "sum",
    "lens_total": "sum",
    "rand_nonzero": "sum",
    "rand_total": "sum",
    "lens_mean": "mean",
    "rand_mean": "mean",
    "p_chi2": "mean",
    "p_binom": "mean",
    "p_poisson": "mean"
}))

from astroquery.simbad import Simbad
from astropy.coordinates import SkyCoord
import astropy.units as u

# Setup custom SIMBAD query with only object type
custom_simbad = Simbad()
custom_simbad.TIMEOUT = 60
custom_simbad.reset_votable_fields()
custom_simbad.add_votable_fields("otype")

# Test coordinates (e.g. random sky)
coord = SkyCoord(ra=150.1, dec=2.3, unit=(u.deg, u.deg), frame='icrs')

# Run SIMBAD query around that position
result = custom_simbad.query_region(coord, radius=10 * u.arcmin)

# Show output
if result is not None:
    print(result[['MAIN_ID', 'OTYPE']])
else:
    print("No objects found.")

import astroquery
print(astroquery.__version__)

from astroquery.simbad import Simbad
from astropy.coordinates import SkyCoord
import astropy.units as u

# Create a custom SIMBAD instance
custom_simbad = Simbad()
custom_simbad.TIMEOUT = 60

# Correct way to reset fields in astroquery 0.4.10
custom_simbad.reset_votable_fields()
custom_simbad.add_votable_fields("otype")

# Test query
coord = SkyCoord(ra=150.1, dec=2.3, unit=(u.deg, u.deg), frame='icrs')
result = custom_simbad.query_region(coord, radius=10 * u.arcmin)

# Display result
if result is not None:
    print(result[['MAIN_ID', 'OTYPE']])
else:
    print("No objects found.")

from astroquery.simbad import Simbad
from astropy.coordinates import SkyCoord
import astropy.units as u

# Custom SIMBAD instance
custom_simbad = Simbad()
custom_simbad.TIMEOUT = 60
custom_simbad.reset_votable_fields()

# ✅ Add necessary fields
custom_simbad.add_votable_fields("main_id", "otype")

# Test query
coord = SkyCoord(ra=150.1, dec=2.3, unit=(u.deg, u.deg), frame='icrs')
result = custom_simbad.query_region(coord, radius=10 * u.arcmin)

# Print results
if result is not None:
    print(result["MAIN_ID", "OTYPE"])
else:
    print("No objects found.")

from astroquery.simbad import Simbad
from astropy.coordinates import SkyCoord
import astropy.units as u

# Create a fresh Simbad instance and explicitly reset fields
custom_simbad = Simbad()
custom_simbad.TIMEOUT = 60
custom_simbad.reset_votable_fields()
custom_simbad.add_votable_fields("main_id")
custom_simbad.add_votable_fields("otype")

# Use test coordinates
coord = SkyCoord(ra=150.1, dec=2.3, unit=(u.deg, u.deg), frame='icrs')
result = custom_simbad.query_region(coord, radius=10 * u.arcmin)

# Show what fields are actually present
print(result.colnames)

# Show preview (only if result exists)
if result is not None:
    print(result.to_pandas().head())
else:
    print("No results found.")

from astroquery.simbad import Simbad
from astropy.coordinates import SkyCoord
import astropy.units as u

# Define the BH-related types
bh_types = {"BH", "BHXRB", "XRB", "BLAZAR", "AGN", "QSO"}

# Custom SIMBAD instance
custom_simbad = Simbad()
custom_simbad.TIMEOUT = 60
custom_simbad.reset_votable_fields()
custom_simbad.add_votable_fields("main_id")
custom_simbad.add_votable_fields("otype")

# Function to count BH-type objects near a coordinate
def count_bh_objects(ra_deg, dec_deg, radius_arcmin=10):
    coord = SkyCoord(ra=ra_deg, dec=dec_deg, unit=(u.deg, u.deg), frame="icrs")
    try:
        result = custom_simbad.query_region(coord, radius=radius_arcmin * u.arcmin)
        if result is None or len(result) == 0:
            return 0
        # Filter by BH-like object types
        bh_count = sum(otype in bh_types for otype in result["otype"])
        return bh_count
    except Exception as e:
        print(f"SIMBAD query failed at RA={ra_deg}, Dec={dec_deg}: {e}")
        return 0

import numpy as np
import pandas as pd
import random
from lenscat import catalog
from astroquery.simbad import Simbad
from astropy.coordinates import SkyCoord
import astropy.units as u
from scipy.stats import chi2_contingency, binomtest, ks_2samp, poisson

# -----------------------------
# 1. Load Catalog & Preprocess
# -----------------------------
print("Loading full catalog from lenscat package...")
df = catalog.to_pandas()
print(f"✅ Total lenses loaded: {len(df):,}")

df['z'] = pd.to_numeric(df['zlens'], errors='coerce')
df_strong = df[df['grading'].isin(['confident', 'probable']) & df['z'].notna()].reset_index(drop=True)
print(f"Strong lenses w/ redshift: {len(df_strong):,}")

# -----------------------------
# 2. SIMBAD Setup
# -----------------------------
bh_types = {"BH", "BHXRB", "XRB", "BLAZAR", "AGN", "QSO"}
custom_simbad = Simbad()
custom_simbad.TIMEOUT = 60
custom_simbad.reset_votable_fields()
custom_simbad.add_votable_fields("main_id")
custom_simbad.add_votable_fields("otype")

# -----------------------------
# 3. BH Count Function
# -----------------------------
def count_bh_objects(ra_deg, dec_deg, radius_arcmin=10):
    coord = SkyCoord(ra=ra_deg, dec=dec_deg, unit=(u.deg, u.deg), frame="icrs")
    try:
        result = custom_simbad.query_region(coord, radius=radius_arcmin * u.arcmin)
        if result is None:
            return 0
        return sum(otype in bh_types for otype in result['otype'])
    except Exception as e:
        print(f"SIMBAD query failed at RA={ra_deg}, Dec={dec_deg}: {e}")
        return 0

# -----------------------------
# 4. Generate Random RA/DEC
# -----------------------------
def generate_random_coords(n, exclude_coords, min_sep_deg=0.2):
    random_coords = []
    attempts = 0
    while len(random_coords) < n and attempts < n * 100:
        ra = np.random.uniform(0, 360)
        dec = np.random.uniform(-30, 30)  # Match lenscat band
        if all(np.hypot(ra - rra, dec - rdec) > min_sep_deg for rra, rdec in exclude_coords):
            random_coords.append((ra, dec))
        attempts += 1
    return random_coords

# -----------------------------
# 5. Batch Process
# -----------------------------
batch_size = 50
radii = [10, 15, 20]  # arcminutes
lens_coords = list(zip(df_strong['RA'], df_strong['DEC']))
all_lens_counts = {r: [] for r in radii}
all_rand_counts = {r: [] for r in radii}

num_batches = int(np.ceil(len(df_strong) / batch_size))
print(f"\nTotal batches: {num_batches}\n")

for batch_num in range(num_batches):
    start, end = batch_num * batch_size, min((batch_num + 1) * batch_size, len(df_strong))
    batch = df_strong.iloc[start:end]
    print(f"🔎 Processing batch {batch_num + 1} ({len(batch)} lenses)...")

    # Generate randoms
    exclude_coords = set(lens_coords)
    rand_coords = generate_random_coords(len(batch), exclude_coords)

    for radius in radii:
        lens_counts = [count_bh_objects(row['RA'], row['DEC'], radius) for _, row in batch.iterrows()]
        rand_counts = [count_bh_objects(ra, dec, radius) for ra, dec in rand_coords]

        all_lens_counts[radius].extend(lens_counts)
        all_rand_counts[radius].extend(rand_counts)

        print(f"▶ Radius: {radius}′")

# -----------------------------
# 6. Summarize & Significance
# -----------------------------
print("\n\U0001f4ca Statistical Summary\n------------------------")
for radius in radii:
    lens = np.array(all_lens_counts[radius])
    rand = np.array(all_rand_counts[radius])

    lens_nonzero = np.sum(lens > 0)
    rand_nonzero = np.sum(rand > 0)

    lens_total = len(lens)
    rand_total = len(rand)

    print(f"Radius: {radius} arcmin")
    print(f"  BH in Lenses: {lens_nonzero}/{lens_total} ({lens_nonzero/lens_total:.1%})")
    print(f"  BH in Random : {rand_nonzero}/{rand_total} ({rand_nonzero/rand_total:.1%})")

    # Chi-squared test
    table = [[lens_nonzero, lens_total - lens_nonzero],
             [rand_nonzero, rand_total - rand_nonzero]]
    chi2, p_chi2, _, _ = chi2_contingency(table)

    # Binomial test
    p_binom = binomtest(lens_nonzero, lens_total, rand_nonzero / rand_total).pvalue

    # Poisson test
    poisson_p = poisson.sf(lens_nonzero - 1, mu=(rand_nonzero / rand_total) * lens_total)

    # KS test for distributions
    ks_stat, ks_p = ks_2samp(lens, rand)

    print(f"    Chi-squared p = {p_chi2:.3e}")
    print(f"    Binomial p    = {p_binom:.3e}")
    print(f"    Poisson p     = {poisson_p:.3e}")
    print(f"    KS test p     = {ks_p:.3e}\n")

import numpy as np
import pandas as pd
import random
from lenscat import catalog
from astroquery.simbad import Simbad
from astropy.coordinates import SkyCoord
import astropy.units as u
from scipy.stats import chi2_contingency, binomtest, ks_2samp, poisson

# -----------------------------
# 1. Load Catalog & Preprocess
# -----------------------------
print("Loading full catalog from lenscat package...")
df = catalog.to_pandas()
print(f"✅ Total lenses loaded: {len(df):,}")

df['z'] = pd.to_numeric(df['zlens'], errors='coerce')
df_strong = df[df['grading'].isin(['confident', 'probable']) & df['z'].notna()].reset_index(drop=True)
print(f"Strong lenses w/ redshift: {len(df_strong):,}")

# -----------------------------
# 2. SIMBAD Setup
# -----------------------------
bh_types = {"BH", "BHXRB", "XRB", "BLAZAR", "AGN", "QSO"}
custom_simbad = Simbad()
custom_simbad.TIMEOUT = 60
custom_simbad.reset_votable_fields()
custom_simbad.add_votable_fields("main_id")
custom_simbad.add_votable_fields("otype")

# -----------------------------
# 3. BH Count Function
# -----------------------------
def count_bh_objects(ra_deg, dec_deg, radius_arcmin=10):
    coord = SkyCoord(ra=ra_deg, dec=dec_deg, unit=(u.deg, u.deg), frame="icrs")
    try:
        result = custom_simbad.query_region(coord, radius=radius_arcmin * u.arcmin)
        if result is None:
            return 0
        return sum(otype in bh_types for otype in result['otype'])
    except Exception as e:
        print(f"SIMBAD query failed at RA={ra_deg}, Dec={dec_deg}: {e}")
        return 0

# -----------------------------
# 4. Generate Random RA/DEC
# -----------------------------
def generate_random_coords(n, exclude_coords, min_sep_deg=0.2):
    random_coords = []
    attempts = 0
    while len(random_coords) < n and attempts < n * 100:
        ra = np.random.uniform(0, 360)
        dec = np.random.uniform(-30, 30)  # Match lenscat band
        if all(np.hypot(ra - rra, dec - rdec) > min_sep_deg for rra, rdec in exclude_coords):
            random_coords.append((ra, dec))
        attempts += 1
    return random_coords

# -----------------------------
# 5. Batch Process
# -----------------------------
batch_size = 50
radii = [10, 15, 20]  # arcminutes
lens_coords = list(zip(df_strong['RA'], df_strong['DEC']))
all_lens_counts = {r: [] for r in radii}
all_rand_counts = {r: [] for r in radii}

num_batches = int(np.ceil(len(df_strong) / batch_size))
print(f"\nTotal batches: {num_batches}\n")

for batch_num in range(num_batches):
    start, end = batch_num * batch_size, min((batch_num + 1) * batch_size, len(df_strong))
    batch = df_strong.iloc[start:end]
    print(f"🔎 Processing batch {batch_num + 1} ({len(batch)} lenses)...")

    # Generate randoms
    exclude_coords = set(lens_coords)
    rand_coords = generate_random_coords(len(batch), exclude_coords)

    for radius in radii:
        lens_counts = [count_bh_objects(row['RA'], row['DEC'], radius) for _, row in batch.iterrows()]
        rand_counts = [count_bh_objects(ra, dec, radius) for ra, dec in rand_coords]

        all_lens_counts[radius].extend(lens_counts)
        all_rand_counts[radius].extend(rand_counts)

        print(f"▶ Radius: {radius}′")

    # Progress reporting every 10 batches and then every 50 after that
    if (batch_num + 1 <= 10) or ((batch_num + 1) % 50 == 0):
        print("\n\U0001f4c8 Intermediate Summary after batch", batch_num + 1)
        for radius in radii:
            lens = np.array(all_lens_counts[radius])
            rand = np.array(all_rand_counts[radius])

            lens_nonzero = np.sum(lens > 0)
            rand_nonzero = np.sum(rand > 0)

            lens_total = len(lens)
            rand_total = len(rand)

            print(f"Radius: {radius} arcmin")
            print(f"  BH in Lenses: {lens_nonzero}/{lens_total} ({lens_nonzero/lens_total:.1%})")
            print(f"  BH in Random : {rand_nonzero}/{rand_total} ({rand_nonzero/rand_total:.1%})")
            print(f"  ➔ Lens total BH objects: {np.sum(lens)}, mean per field: {np.mean(lens):.2f}")
            print(f"  ➔ Rand total BH objects: {np.sum(rand)}, mean per field: {np.mean(rand):.2f}")

# -----------------------------
# 6. Final Summary & Significance
# -----------------------------
print("\n\U0001f4ca Statistical Summary\n------------------------")
for radius in radii:
    lens = np.array(all_lens_counts[radius])
    rand = np.array(all_rand_counts[radius])

    lens_nonzero = np.sum(lens > 0)
    rand_nonzero = np.sum(rand > 0)

    lens_total = len(lens)
    rand_total = len(rand)

    print(f"Radius: {radius} arcmin")
    print(f"  BH in Lenses: {lens_nonzero}/{lens_total} ({lens_nonzero/lens_total:.1%})")
    print(f"  BH in Random : {rand_nonzero}/{rand_total} ({rand_nonzero/rand_total:.1%})")
    print(f"  ➔ Lens total BH objects: {np.sum(lens)}, mean per field: {np.mean(lens):.2f}")
    print(f"  ➔ Rand total BH objects: {np.sum(rand)}, mean per field: {np.mean(rand):.2f}")

    # Chi-squared test
    table = [[lens_nonzero, lens_total - lens_nonzero],
             [rand_nonzero, rand_total - rand_nonzero]]
    chi2, p_chi2, _, _ = chi2_contingency(table)

    # Binomial test
    p_binom = binomtest(lens_nonzero, lens_total, rand_nonzero / rand_total).pvalue

    # Poisson test
    poisson_p = poisson.sf(lens_nonzero - 1, mu=(rand_nonzero / rand_total) * lens_total)

    # KS test for distributions
    ks_stat, ks_p = ks_2samp(lens, rand)

    print(f"    Chi-squared p = {p_chi2:.3e}")
    print(f"    Binomial p    = {p_binom:.3e}")
    print(f"    Poisson p     = {poisson_p:.3e}")
    print(f"    KS test p     = {ks_p:.3e}\n")